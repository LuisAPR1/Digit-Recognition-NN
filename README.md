# Neural Network Implementation in Java

A simple feedforward neural network implementation in Java with backpropagation learning algorithm. This project demonstrates the core concepts of artificial neural networks including forward propagation, backpropagation, and weight optimization.

## Features

- **Feedforward Neural Network**: Implements a multi-layer perceptron with configurable architecture
- **Backpropagation Learning**: Uses gradient descent with backpropagation for training
- **Sigmoid Activation Function**: Implements sigmoid activation and its derivative
- **Weight Persistence**: Save and load trained weights to/from CSV files
- **Training Monitoring**: Tracks Mean Squared Error (MSE) during training
- **Interactive Testing**: Console-based interface for training and testing

## Project Structure

```
src/
├── Main.java           # Main application with training and testing logic
├── NeuralNetwork.java  # Core neural network implementation
├── Layer.java          # Neural network layer abstraction
└── Neuron.java         # Individual neuron implementation
```

## Classes Overview

### Neuron
- Represents a single neuron with weights, bias, and activation function
- Implements sigmoid activation and its derivative
- Handles forward propagation calculations

### Layer
- Manages a collection of neurons
- Handles forward propagation for the entire layer
- Initializes neurons with random weights

### NeuralNetwork
- Main neural network class that orchestrates training and testing
- Implements backpropagation algorithm
- Provides methods for saving/loading weights
- Handles MSE calculation and convergence checking

### Main
- Application entry point
- Provides different execution modes (training, testing, interactive)
- Handles data loading from CSV files
- Implements input normalization

## Usage

### Training Mode
```java
// Train the network with new data
mainInstance.exercise5(true);
```

### Testing Mode
```java
// Test with pre-trained weights
mainInstance.exercise5(false);
```

### Interactive Mode
```java
// Interactive testing with console input
mainInstance.mooshake(false);
```

## Configuration

The network can be configured by modifying the following parameters in `Main.java`:

- **Learning Rate**: `0.1` (default)
- **MSE Threshold**: `0.0001` (convergence criterion)
- **Network Architecture**: Currently set to 1 input neuron with 400 connections
- **Training Data**: Lines 1-280 from dataset.csv
- **Test Data**: Lines 1-800 from dataset.csv

## Data Format

### Input Data (dataset.csv)
- CSV format with 400 features per row
- Values should be normalized between 0 and 1
- Each row represents one training/test sample

### Target Data (labels.csv)
- CSV format with single target value per row
- Binary classification (0 or 1)
- Must match the number of input samples

## Output Files

- **pesos.csv**: Saved network weights after training
- **mse_values.txt**: MSE values recorded during training epochs

## Training Process

1. **Forward Pass**: Calculate network output for each training sample
2. **Error Calculation**: Compute difference between predicted and actual output
3. **Backward Pass**: Calculate gradients using backpropagation
4. **Weight Update**: Adjust weights and biases using gradient descent
5. **Convergence Check**: Monitor MSE and stop when threshold is reached

## Testing and Evaluation

The network provides:
- **Accuracy Percentage**: Correct predictions vs total predictions
- **Root Mean Square Error**: Average prediction error
- **Detailed Output**: Expected vs predicted values for each test sample

## Requirements

- Java 8 or higher
- CSV data files (dataset.csv and labels.csv) in the parent directory
- No external dependencies required

## Example Output

```
Testing the network:
Input 1: Expected: 1, Predicted: 0.85
Input 2: Expected: 0, Predicted: 0.12
...

Accuracy: 87.50%
250 CORRETOS DE 800
VALOR DO ERRO - 0.23
```

## Notes

- The current implementation uses a single hidden layer architecture
- Input normalization is applied to ensure values are between 0 and 1
- Training stops when MSE falls below threshold or starts increasing
- Weights are automatically saved after successful training

This README was generated by AI Claude Sonnet 3.7
